{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Some pre-requisites and things I had to install, mostly written here so I don't forget and that they're all in one place"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2813d5b3d5abbd8f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-09T17:11:27.737910Z",
     "start_time": "2024-04-09T17:11:27.732909Z"
    }
   },
   "outputs": [],
   "source": [
    "##Run these in the console if you don't already have them installed <3\n",
    "# pip install -U pip setuptools wheel #to get pip\n",
    "# pip install torch #pytorch \n",
    "# pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 #this version with CUDA required for gemma\n",
    "# pip install transformers datasets #huggingface transformers and datasets\n",
    "# pip install accelerate #required to make gemma work\n",
    "\n",
    "\n",
    "# pip install -U spacy #to get spacy\n",
    "# pip install lemminflect #to get lemmainflect -> eng only (even pyinflect recommends using lemminflect instead)\n",
    "# python -m spacy download en_core_web_md ##md size is minimum that has vectors for words\n",
    "# python -m spacy download pl_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T17:40:52.927761Z",
     "start_time": "2024-04-09T17:40:50.952315Z"
    }
   },
   "id": "b92603dff9316b45",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate a sentence containing a given word"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "986820a3a60fe64d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c81e70653f804bdab0a7f9ce99276cd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "#this model is gated, so... logging in to huggingface with #huggingface-cli login# is necessary\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\", device_map=\"auto\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T17:45:38.710504Z",
     "start_time": "2024-04-09T17:45:26.215674Z"
    }
   },
   "id": "69846e330ca32e3b",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Write me an example sentence that contains the word 'dancing'.\n",
      "\n",
      "The dancing flames illuminated the night\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Write me an example sentence that contains the word 'dancing'.\" #...it's the same everytime x_x\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids)\n",
    "print(tokenizer.decode(outputs[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T17:45:50.780239Z",
     "start_time": "2024-04-09T17:45:45.577061Z"
    }
   },
   "id": "78eb98d2b398be71",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "The same thing but Polish"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dfd868bcf20def8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"Proszę napisać mi zdanie zawierające słowo 'taniec' se wojan słod woja. Eię u'asni paz-�\"}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(model=\"gpt2\") #generates text only, does not understand requests\n",
    "\n",
    "output = pipe(\"Proszę napisać mi zdanie zawierające słowo 'taniec'\") #albo tańczący\n",
    "print(output)\n",
    "#lollllll nothing about this works, it makes actual nonsense XD Not that I expected it to work, but still"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T16:43:56.847835Z",
     "start_time": "2024-04-09T16:43:54.740366Z"
    }
   },
   "id": "2e64a6f379c50106",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4307c8192d823c24"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

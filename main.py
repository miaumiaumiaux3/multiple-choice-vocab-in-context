# pip install -U spacy #to get spacy
# pip install lemminflect #to get lemmainflect -> eng only (even pyinflect recommends using lemminflect instead)
# python -m spacy download en_core_web_md ##md size is minimum that has vectors for words
# python -m spacy download pl_core_news_md

import string
import spacy
import lemminflect
from lemminflect import getLemma, getAllLemmas, getInflection, getAllInflections #might not need, as it can be used as a spaCy extension
import collections
from collections.abc import Iterable

def flatten(xs): #flatten a list of lists
    for x in xs:
        if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):
            yield from flatten(x)
        else:
            yield x

def clean_sentence(sentence):
    '''make lowercase, remove punctuation and split into words'''
    sentence = sentence.lower().translate(str.maketrans('', '', string.punctuation))
    word_list = sentence.split()
    return word_list

#### either we will ask for language here, or we will make seperate python files for each language ###
#for now, just testing with english

# Load the en_core_web_md model
nlp = spacy.load("en_core_web_md")

# Get target word (later from user)
word = "dancing" #needs to be able to work for any word in any form

###### Check that the word is a noun, adjective, or verb before we go through this whole song and dance ######

# Get target word's lemma and all inflections
print(getAllLemmas(word, upos = None))
word_lemmas = list(getAllLemmas(word, upos = None).values())

####first entry is the most common lemma, but we should test other words and see if we always produce the same inflections
print(word_lemmas, "first entry: ", word_lemmas[0][0])
main_lemma = word_lemmas[0][0]

#get all inflections of the first lemma
word_inflections = getAllInflections(main_lemma, upos=None)
print(word_inflections)

word_inflection_list = set(flatten(list(word_inflections.values())))
print(word_inflection_list)

# Generate sentence from target word
#this will be generated by the model, but for now we'll grab the first sentence generated by our current mvp model
generated_sentence = "Amidst the lively melody, people of all ages were dancing joyfully together at the outdoor festival."

## Make sure the sentence contains a registered inflection of the target word, if not, generate a new sentence
words_in_gen_sentence = clean_sentence(generated_sentence)

#check if any of the inflections are in the generated sentence
inflected_word = None
inflection_in_sentence = False
for inf in word_inflection_list:
    if inf in words_in_gen_sentence:
        inflection_in_sentence = True
        inflected_word = inf
        break

print(inflected_word, inflection_in_sentence)

if not inflection_in_sentence:
    print("No inflection of the target word found in the generated sentence. Generate a new sentence.")

#process generated_sentence with spaCy
doc = nlp(generated_sentence)

# Get the index of the target word in the sentence
word_index = None
for token in doc:
    if token.text == inflected_word:
        word_index = token.i
        break

# Get the POS tag of the target word
word_pos = doc[word_index].pos_
word_tag = doc[word_index].tag_
print(word, inflected_word, word_index, word_pos, word_tag)

# Search for words in the dictionary with the same POS that are very dissimilar to the target word

###Can we do it randomly? Or do we need to copy the entire massive dictionary and add data to each entry?###


